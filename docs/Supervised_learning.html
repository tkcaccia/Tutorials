<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Stefano Cacciatore" />

<meta name="date" content="2024-09-18" />

<title>Module 4: Supervised Learning</title>

<script src="site_libs/header-attrs-2.27/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">R Tutorial</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Install.html">R install</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Basic
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Introduction.html">Introduction to R and RStudio</a>
    </li>
    <li>
      <a href="Statistics.html">Statistics</a>
    </li>
    <li>
      <a href="Visualisation.html">Data Visualisation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Multivariate analysis
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Supervised_learning.html">Supervised Learning</a>
    </li>
    <li>
      <a href="Unsupervised_Learning.html">Unsupervised Learning</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Applications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TCGA.html">TCGA</a>
    </li>
    <li>
      <a href="Single-cell.html">Single-cell</a>
    </li>
  </ul>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/oliverdesousa/R_Tutorials">
    <span class="fab fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Module 4: Supervised Learning</h1>
<h4 class="author">Stefano Cacciatore</h4>
<h4 class="date">September 18, 2024</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2024-09-18
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>Tutorials/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.1). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20240905code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20240905)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20240905code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20240905)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomtkcacciaTutorialstreea7f82c5b849c08d114265e6dd34749c2b1fe6f2dtargetblanka7f82c5a">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/tkcaccia/Tutorials/tree/a7f82c5b849c08d114265e6dd34749c2b1fe6f2d" target="_blank">a7f82c5</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomtkcacciaTutorialstreea7f82c5b849c08d114265e6dd34749c2b1fe6f2dtargetblanka7f82c5a"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/tkcaccia/Tutorials/tree/a7f82c5b849c08d114265e6dd34749c2b1fe6f2d" target="_blank">a7f82c5</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    data/.DS_Store

Unstaged changes:
    Deleted:    data/COADREAD.clin.merged.picked.txt
    Deleted:    data/COADREAD.rnaseqv2__illuminahiseq_rnaseqv2__unc_edu__Level_3__RSEM_genes_normalized__data.data.txt

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown (<code>analysis/Supervised_learning.Rmd</code>)
and HTML (<code>docs/Supervised_learning.html</code>) files. If you’ve
configured a remote Git repository (see <code>?wflow_git_remote</code>),
click on the hyperlinks in the table below to view the files as they
were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/tkcaccia/Tutorials/a7f82c5b849c08d114265e6dd34749c2b1fe6f2d/docs/Supervised_learning.html" target="_blank">a7f82c5</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-18
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/tkcaccia/Tutorials/83f8d4e746d713066af6582f8ceaa6cccb31b6d1/docs/Supervised_learning.html" target="_blank">83f8d4e</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/tkcaccia/Tutorials/159190a0f38e56bd72f396b250277a4a3b3b74bf/docs/Supervised_learning.html" target="_blank">159190a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/tkcaccia/Tutorials/6d23cdb74595a082fc1d86dd7d29bc5ce65703f1/docs/Supervised_learning.html" target="_blank">6d23cdb</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/tkcaccia/Tutorials/6301d0ade76fe73d7038cd24aecc9f9f9df2794e/docs/Supervised_learning.html" target="_blank">6301d0a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/tkcaccia/Tutorials/897778af75990c4268c8b31f4717b5182769c81b/docs/Supervised_learning.html" target="_blank">897778a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/tkcaccia/Tutorials/blob/9a91f513ba75f8fd450a133bae23dfff825fc9e0/analysis/Supervised_learning.Rmd" target="_blank">9a91f51</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
<td>
Start my new project
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="supervised-learning" class="section level1">
<h1>Supervised Learning</h1>
<p>Supervised learning is learning in which we teach or train the
machine using data that is well labeled meaning some data is already
tagged with the correct answer.</p>
<p>The machine is provided with a test dataset so that the supervised
learning algorithm analyses the training data and produces a correct
outcome from labeled data.</p>
<p>Supervised learning itself is composed of;</p>
<ul>
<li><p><code>Regression</code>, where the output is numerical</p></li>
<li><p><code>Classification</code>, where the output is
categorical</p></li>
</ul>
<div id="regression" class="section level2">
<h2>Regression</h2>
<p>Regression analysis is a statistical technique used to model and
analyze the relationship between a dependent variable and one
(<strong><code>univariate regression</code></strong>) or more
independent
variables(<strong><code>multivariate regression</code></strong>).</p>
<div id="simple-linear-regression" class="section level3">
<h3>Simple Linear Regression</h3>
<p>Simple linear regression involves a single independent variable and
fits the equation;</p>
<center>
<span class="math inline">\(y=b_0 +b_1x\)</span>
</center>
<p>where;</p>
<ul>
<li><p><span class="math inline">\(y\)</span> is the dependent
variable</p></li>
<li><p><span class="math inline">\(x\)</span> is the independent
variable</p></li>
<li><p><span class="math inline">\(b_0\)</span> is the
intercept</p></li>
<li><p><span class="math inline">\(b_1\)</span> is the slope of the
linear graph</p></li>
</ul>
<div id="step-1-loading-libraries-and-import-the-dataset"
class="section level4">
<h4>Step 1: Loading libraries and import the dataset</h4>
<p>The <code>caret</code> library is important for data partitioning,
model training and evaluation</p>
<pre class="r"><code>library(caret)   

# Load the dataset
df &lt;- read.csv(&#39;data/tumor_size_patient_survival.csv&#39;)

# Display the first rows
head(df)</code></pre>
<pre><code>  tumor_size patient_survival
1       26.3            279.9
2       12.2            347.4
3       41.5            227.3
4       21.5            330.1
5       28.0            292.1
6       22.2            310.6</code></pre>
<p>Functions like <code>head()</code>, <code>summary()</code>,
<code>str()</code> can be used to get an overview of the data.</p>
</div>
<div id="step-2-data-pre-processing" class="section level4">
<h4>Step 2: Data Pre-Processing</h4>
<p>This step involves;</p>
<ul>
<li><p>handling missing values by either removing missing values or
mean, median or mode imputation</p></li>
<li><p>encoding categorical variables</p></li>
<li><p>normalising and standardising numerical features</p></li>
</ul>
</div>
<div id="step-3-splitting-the-dataset-into-training-and-test-set"
class="section level4">
<h4>Step 3: Splitting the dataset into training and test set</h4>
<p>Usually the dataset can be split into 75% for training and 25% for
test. This facilitates data generalisation and avoids over fitting.</p>
<pre class="r"><code>set.seed(45)  # for reproducibility
trainIndex &lt;- createDataPartition(df$patient_survival, p = 0.75, list = FALSE)
trainData &lt;- df[trainIndex, ]
testData &lt;- df[-trainIndex, ]</code></pre>
</div>
<div id="step-4-train-the-linear-regression-model"
class="section level4">
<h4>Step 4: Train the linear regression model</h4>
<p>This involves fitting the model to the training set using the
<code>lm()</code> function</p>
<pre class="r"><code>model &lt;- lm(patient_survival ~ tumor_size, data = trainData)

# Extract coefficients
coefficients &lt;- coef(model)
coefficients</code></pre>
<pre><code>(Intercept)  tumor_size 
 395.077138   -3.853336 </code></pre>
<p>The linear equation that fits to the data in our training set is</p>
<center>
<span class="math inline">\(y = 395 - 4x\)</span>
</center>
</div>
<div id="step-5-evaluating-the-model" class="section level4">
<h4>Step 5: Evaluating the model</h4>
<p>This involves assessing the performance of the model on the testing
set. There are various metrics for model evaluation including;</p>
<ul>
<li><p>Mean Absolute Error (MAE)</p></li>
<li><p>Mean Squared Error (MSE)</p></li>
<li><p>Root Mean Squared Error (RMSE)</p></li>
<li><p>R-Squared (R<sup>2</sup>)Score</p></li>
</ul>
<pre class="r"><code>test_predictions &lt;- predict(model, newdata = testData)
mae &lt;- MAE(test_predictions, testData$patient_survival)
rmse &lt;- RMSE(test_predictions, testData$patient_survival)
r2_score &lt;- summary(model)$r.squared

cat(&#39;MAE on test set (in days): &#39;, mae, &quot;\n&quot;,
  &#39;RMSE on test set (in days): &#39;, rmse, &quot;\n&quot;,
  &#39;R-Squared Score: &#39;, r2_score)</code></pre>
<pre><code>MAE on test set (in days):  13.04724 
 RMSE on test set (in days):  15.93548 
 R-Squared Score:  0.820814</code></pre>
</div>
<div id="step-6-visualising-the-model" class="section level4">
<h4>Step 6: Visualising the model</h4>
<pre class="r"><code>library(ggplot2)

# Add a column to differentiate between training and test data
trainData$dataset &lt;- &quot;Training&quot;
testData$dataset &lt;- &quot;Test&quot;

# Combine train and test data into a single dataframe for plotting
combinedData &lt;- rbind(trainData, testData)

# Create a scatter plot with regression line for both training and test sets
ggplot(combinedData, aes(x = tumor_size, y = patient_survival, color = dataset, shape = dataset)) +
  geom_point(alpha = 0.7) +
  geom_smooth(data = trainData, aes(x = tumor_size, y = patient_survival), method = &quot;lm&quot;, se = FALSE, color = &quot;#00008B&quot;) +
  labs(title = &quot;Relationship between Tumor Size and Patient Survival&quot;,
       x = &quot;Tumor Size (mm)&quot;,
       y = &quot;Patient Survival (Days)&quot;) +
  theme_minimal() +
  scale_color_manual(values = c(&quot;Training&quot; = &quot;blue&quot;, &quot;Test&quot; = &quot;red&quot;)) +
  scale_shape_manual(values = c(&quot;Training&quot; = 16, &quot;Test&quot; = 16)) +
  guides(color = guide_legend(title = &quot;Dataset&quot;),
         shape = guide_legend(title = &quot;Dataset&quot;))</code></pre>
<pre><code>`geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="figure/Supervised_learning.Rmd/linear_visual-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-linear_visual-1">
Past versions of linear_visual-1.png
</button>
</p>
<div id="fig-linear_visual-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/tkcaccia/Tutorials/blob/897778af75990c4268c8b31f4717b5182769c81b/docs/figure/Supervised_learning.Rmd/linear_visual-1.png" target="_blank">897778a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div id="multivariate-linear-regression" class="section level3">
<h3>Multivariate Linear Regression</h3>
<p>Most real-life scenarios are characterised by multivariate or
high-dimensional features where more than one independent variable
influences the target or dependent variable. Multi variate algorithms
fit the model;</p>
<center>
<span class="math inline">\(y = b_0 + b_1x_1 +b_2x_2 + b_3x_3 + ... +
b_nx_n\)</span>
</center>
<p>The <code>mpg</code> dataset from the <code>ggplot2</code> package
can be used for multivariate regression. It includes information on car
attributes. we will choose some relevant attributes to predict
<code>hwy</code>, miles per gallon (MPG).</p>
<div id="step-1-loading-the-dataset" class="section level4">
<h4>Step 1: Loading the dataset</h4>
<pre class="r"><code># Load the dataset
library(ggplot2)
data(mpg)
df &lt;- mpg
head(df)</code></pre>
<pre><code># A tibble: 6 × 11
  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class 
  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 
1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa…
2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa…
3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa…
4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa…
5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa…
6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa…</code></pre>
<p>We can choose predictors; <code>displ</code> - (engine displacement),
<code>cyl</code> - (number of cylinders), <code>year</code> - (year of
the car) and <code>class</code> - (type of car)</p>
</div>
<div id="step-2-splitting-and-preparing-the-dataset"
class="section level4">
<h4>Step 2: Splitting and preparing the dataset</h4>
<pre class="r"><code>library(caret)

set.seed(30) # for reproducibility

# Split the data into training and testing sets
trainIndex &lt;- createDataPartition(df$hwy, p = 0.75, list = FALSE)
trainData &lt;- df[trainIndex, ]
testData &lt;- df[-trainIndex, ]</code></pre>
</div>
<div id="step-3-fitting-the-model" class="section level4">
<h4>Step 3: Fitting the model</h4>
<pre class="r"><code>model_mv &lt;- lm(hwy ~ displ + cyl + year + class, data = trainData)
summary(model_mv) </code></pre>
<pre><code>
Call:
lm(formula = hwy ~ displ + cyl + year + class, data = trainData)

Residuals:
    Min      1Q  Median      3Q     Max 
-5.1700 -1.5322 -0.1473  1.0249 15.1030 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     -183.14115   91.73394  -1.996 0.047511 *  
displ             -1.06300    0.52272  -2.034 0.043576 *  
cyl               -1.11663    0.36516  -3.058 0.002596 ** 
year               0.11135    0.04593   2.424 0.016399 *  
classcompact      -4.06888    1.94849  -2.088 0.038295 *  
classmidsize      -3.82081    1.89582  -2.015 0.045468 *  
classminivan      -6.82814    1.98819  -3.434 0.000749 ***
classpickup      -10.55172    1.76709  -5.971 1.38e-08 ***
classsubcompact   -3.29990    1.90675  -1.731 0.085364 .  
classsuv          -9.35511    1.70649  -5.482 1.53e-07 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.7 on 167 degrees of freedom
Multiple R-squared:  0.8091,    Adjusted R-squared:  0.7989 
F-statistic: 78.67 on 9 and 167 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="step-4-evaluating-the-model" class="section level4">
<h4>Step 4: Evaluating the model</h4>
<pre class="r"><code>test_predictions_mv &lt;- predict(model_mv, newdata = testData)
mae &lt;- MAE(test_predictions_mv, testData$hwy)
rmse &lt;- RMSE(test_predictions_mv, testData$hwy)
r2_score &lt;- summary(model)$r.squared

cat(&#39;MAE on test set (in days): &#39;, mae, &quot;\n&quot;,
  &#39;RMSE on test set (in days): &#39;, rmse, &quot;\n&quot;,
  &#39;R-Squared Score: &#39;, r2_score)</code></pre>
<pre><code>MAE on test set (in days):  1.804035 
 RMSE on test set (in days):  2.325899 
 R-Squared Score:  0.820814</code></pre>
</div>
</div>
</div>
<div id="classification" class="section level2">
<h2>Classification</h2>
<div id="logistic-regression-lr" class="section level3">
<h3>Logistic Regression (LR)</h3>
<p>logistic regression is classification algorithm used to predict a
binary class label (for example, 0 or 1, cancer or no cancer).</p>
<p>LR has much in common with linear regression, the difference being
that linear regression is used to predict a
<code>continuous target</code>, whereas logistic regression is used to
predict a <code>categorical target</code>.</p>
<p>We can modify the <code>iris</code> dataset to demonstrate logistic
regression for binary classification by classifying whether a flower is
of “setosa” species or not.</p>
<div id="step-1-data-preparation" class="section level4">
<h4>Step 1: Data Preparation</h4>
<p>Converting the iris data set into binary classification by creating a
variable <code>Issetosa</code></p>
<pre class="r"><code>data(iris)
head(iris)</code></pre>
<pre><code>  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa</code></pre>
<pre class="r"><code>iris$IsSetosa &lt;- ifelse(iris$Species == &quot;setosa&quot;, 1, 0)

head(iris)</code></pre>
<pre><code>  Sepal.Length Sepal.Width Petal.Length Petal.Width Species IsSetosa
1          5.1         3.5          1.4         0.2  setosa        1
2          4.9         3.0          1.4         0.2  setosa        1
3          4.7         3.2          1.3         0.2  setosa        1
4          4.6         3.1          1.5         0.2  setosa        1
5          5.0         3.6          1.4         0.2  setosa        1
6          5.4         3.9          1.7         0.4  setosa        1</code></pre>
</div>
<div id="step-2-splitting-the-dataset" class="section level4">
<h4>Step 2: Splitting the dataset</h4>
<p>Split the dataset into training (75%) and test (25%) sets</p>
<pre class="r"><code>library(caret)
set.seed(123) # for reproducibility

#
train_index &lt;- createDataPartition(iris$IsSetosa, p = 0.75, list = FALSE)
train_data &lt;- iris[train_index, ]
test_data &lt;- iris[-train_index, ]</code></pre>
</div>
<div id="step-3-fitting-the-logistic-regression-model"
class="section level4">
<h4>Step 3: Fitting the logistic regression model</h4>
<p>We shall predict <code>IsSetosa</code> using
<code>Sepal.Length</code> and <code>Sepal.Width</code></p>
<pre class="r"><code>model_lr &lt;- glm(IsSetosa ~ Sepal.Length + Sepal.Width, data = train_data, family = binomial)

summary(model_lr)</code></pre>
<pre><code>
Call:
glm(formula = IsSetosa ~ Sepal.Length + Sepal.Width, family = binomial, 
    data = train_data)

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)     442.8   144901.2   0.003    0.998
Sepal.Length   -165.6    51459.9  -0.003    0.997
Sepal.Width     139.8    51477.0   0.003    0.998

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1.4431e+02  on 112  degrees of freedom
Residual deviance: 2.1029e-08  on 110  degrees of freedom
AIC: 6

Number of Fisher Scoring iterations: 25</code></pre>
</div>
<div id="step-4-making-predictions" class="section level4">
<h4>Step 4: Making Predictions</h4>
<pre class="r"><code># Make predictions on the training data
test_predictions &lt;- predict(model_lr, newdata = test_data, type = &quot;response&quot;)

# Convert the predicted probabilities to binary outcomes
predicted_class &lt;- ifelse(test_predictions &gt; 0.5, 1, 0)

predicted_class</code></pre>
<pre><code>  1   2   3   5  11  18  19  28  33  36  48  49  55  56  57  58  59  61  62  65 
  1   1   1   1   1   1   1   1   1   1   1   1   0   0   0   0   0   0   0   0 
 66  70  77  83  84  94  95  98 100 105 111 113 116 125 131 135 141 
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 </code></pre>
</div>
<div id="step-5-evaluating-the-model-1" class="section level4">
<h4>Step 5: Evaluating the model</h4>
<p><strong>Confusion matrix</strong></p>
<p>A confusion matrix is a 2×2 table that shows the predicted values
from the model vs. the actual values from the test dataset.</p>
<p>It is a common way to evaluate the performance of a logistic
regression model.</p>
<pre class="r"><code>library(caret)

# Create a confusion matrix using caret
conf_matrix &lt;- confusionMatrix(as.factor(predicted_class), as.factor(test_data$IsSetosa))
print(conf_matrix)</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 25  0
         1  0 12
                                     
               Accuracy : 1          
                 95% CI : (0.9051, 1)
    No Information Rate : 0.6757     
    P-Value [Acc &gt; NIR] : 5.016e-07  
                                     
                  Kappa : 1          
                                     
 Mcnemar&#39;s Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.6757     
         Detection Rate : 0.6757     
   Detection Prevalence : 0.6757     
      Balanced Accuracy : 1.0000     
                                     
       &#39;Positive&#39; Class : 0          
                                     </code></pre>
<pre class="r"><code>library(ggplot2)
library(reshape2)

# Convert confusion matrix to a dataframe
conf_matrix_df &lt;- as.data.frame(conf_matrix$table)

# Create a heatmap using ggplot2
ggplot(data = conf_matrix_df, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = 1) +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;steelblue&quot;) +
  theme_minimal() +
  labs(title = &quot;Confusion Matrix&quot;, x = &quot;Actual&quot;, y = &quot;Predicted&quot;)</code></pre>
<p><img src="figure/Supervised_learning.Rmd/PLOT_CONF-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-PLOT_CONF-1">
Past versions of PLOT_CONF-1.png
</button>
</p>
<div id="fig-PLOT_CONF-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/tkcaccia/Tutorials/blob/897778af75990c4268c8b31f4717b5182769c81b/docs/figure/Supervised_learning.Rmd/PLOT_CONF-1.png" target="_blank">897778a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li><strong><em>Sensitivity:</em></strong> The “true positive rate” –
the measure of how well the model correctly predicted positive
cases.</li>
</ul>
<center>
<span class="math inline">\(Sensitivity = \frac{Actual Positive}{Actual
Positive + False Negative}\)</span>
</center>
<ul>
<li><strong><em>Specificity:</em></strong> The “true negative rate” –
the measure of how well the model correctly predicted positive
cases.</li>
</ul>
<center>
<span class="math inline">\(Specificity = \frac{Actual Negative}{Actual
Negative + False Positive}\)</span>
</center>
<ul>
<li><strong><em>Total miss-classification rate:</em></strong> The
percentage of total incorrect classifications made by the model.</li>
</ul>
<div id="receiver-operating-characteristic-curve-roc"
class="section level5">
<h5><strong>Receiver-operating characteristic curve (ROC)</strong></h5>
<p>The ROC curve is a visual representation of model performance across
all thresholds.</p>
<p>The ROC curve is drawn by calculating the true positive rate (TPR)
and false positive rate (FPR) at every possible threshold, then graphing
TPR over FPR</p>
</div>
<div id="area-under-the-curve-auc" class="section level5">
<h5><strong>Area under the curve (AUC)</strong></h5>
<p>The area under the ROC curve (AUC) represents the probability that
the model, if given a randomly chosen positive and negative example,
will rank the positive higher than the negative.</p>
<pre class="r"><code>library(pROC)
# Create ROC curve
roc_curve &lt;- roc(test_data$IsSetosa, test_predictions)

# Plot ROC curve
plot(roc_curve, main = &quot;ROC Curve&quot;, col = &quot;blue&quot;, lwd = 2)</code></pre>
<p><img src="figure/Supervised_learning.Rmd/ROC-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-ROC-1">
Past versions of ROC-1.png
</button>
</p>
<div id="fig-ROC-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/tkcaccia/Tutorials/blob/897778af75990c4268c8b31f4717b5182769c81b/docs/figure/Supervised_learning.Rmd/ROC-1.png" target="_blank">897778a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code># Compute AUC
auc_value &lt;- auc(roc_curve)
print(paste(&quot;AUC: &quot;, round(auc_value, 4)))</code></pre>
<pre><code>[1] &quot;AUC:  1&quot;</code></pre>
</div>
</div>
</div>
<div id="k-nearest-neighbors-knn" class="section level3">
<h3>k-Nearest Neighbors (kNN)</h3>
<p>K-nearest neighbors works by directly measuring the (Euclidean)
distance between observations and inferring the class of unlabeled data
from the class of its nearest neighbors.</p>
<p>Typically in machine learning, there are two clear steps, where one
first <code>trains</code> a model and then uses the model to predict new
outputs (class labels in this case). In the <code>kNN</code>, these two
steps are combined into a single function call to <code>knn</code>.</p>
<p>Lets draw a set of 50 random iris observations to train the model and
predict the species of another set of 50 randomly chosen flowers. The
knn function takes the training data, the new data (to be inferred) and
the labels of the training data, and returns (by default) the predicted
class.</p>
<pre class="r"><code>set.seed(12L)
train &lt;- sample(150, 50)
test &lt;- sample(150, 50)
library(&quot;class&quot;)
knnres &lt;- knn(iris[train, -5], iris[test, -5], iris$Species[train])
head(knnres)</code></pre>
<pre><code>[1] versicolor setosa     versicolor setosa     setosa     setosa    
Levels: setosa versicolor virginica</code></pre>
</div>
</div>
<div id="tree-based-methods" class="section level2">
<h2>Tree-based Methods</h2>
<p>Tree-based methods are supervised learning algorithms that partition
data into subsets based on feature values.</p>
<p>Types of Tree-based methods;</p>
<ul>
<li><p><strong>Decision trees:</strong> In these models where each
internal node represents a feature test, each branch represents the
outcome of the test, and each leaf node represents a class label or a
continuous value</p></li>
<li><p><strong>Ensemble Methods:</strong> These methods combine multiple
decision trees to improve performance. Examples include; Random Forest
model, boosting models (Xboost)</p></li>
</ul>
<div id="decision-trees" class="section level3">
<h3>Decision Trees</h3>
<p>Decision trees can be used as classification or regression
algorithms.</p>
<p>Let us classify the species of iris flowers based on the features in
the dataset.</p>
<div id="step-1-loading-libraries-and-the-dataset"
class="section level4">
<h4>Step 1: Loading Libraries and the dataset</h4>
<pre class="r"><code>#install.packages(&quot;rpart.plot&quot;)
#install.packages(&quot;randomForest&quot;)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)

# Load the iris dataset
data(iris)</code></pre>
</div>
<div id="step-2-fitting-the-decision-tree-model" class="section level4">
<h4>Step 2: Fitting the decision tree model</h4>
<pre class="r"><code>model_tree &lt;- rpart(Species ~ ., data = iris, method = &quot;class&quot;)</code></pre>
</div>
<div id="step-3-plotting-the-decision-tree" class="section level4">
<h4>Step 3: Plotting the decision tree</h4>
<pre class="r"><code>rpart.plot(model_tree, main = &quot;Decision Tree for Iris Dataset&quot;)</code></pre>
<p><img src="figure/Supervised_learning.Rmd/tree_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-tree_plot-1">
Past versions of tree_plot-1.png
</button>
</p>
<div id="fig-tree_plot-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/tkcaccia/Tutorials/blob/897778af75990c4268c8b31f4717b5182769c81b/docs/figure/Supervised_learning.Rmd/tree_plot-1.png" target="_blank">897778a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="step-4-making-predictions-and-model-evaluation"
class="section level4">
<h4>Step 4: Making predictions and model evaluation</h4>
<pre class="r"><code>tree_predictions &lt;- predict(model_tree, type = &quot;class&quot;)
conf_matrix_tree &lt;- confusionMatrix(tree_predictions, iris$Species)
print(&quot;Decision Tree Confusion Matrix: &quot;)</code></pre>
<pre><code>[1] &quot;Decision Tree Confusion Matrix: &quot;</code></pre>
<pre class="r"><code>print(conf_matrix_tree)</code></pre>
<pre><code>Confusion Matrix and Statistics

            Reference
Prediction   setosa versicolor virginica
  setosa         50          0         0
  versicolor      0         49         5
  virginica       0          1        45

Overall Statistics
                                         
               Accuracy : 0.96           
                 95% CI : (0.915, 0.9852)
    No Information Rate : 0.3333         
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
                                         
                  Kappa : 0.94           
                                         
 Mcnemar&#39;s Test P-Value : NA             

Statistics by Class:

                     Class: setosa Class: versicolor Class: virginica
Sensitivity                 1.0000            0.9800           0.9000
Specificity                 1.0000            0.9500           0.9900
Pos Pred Value              1.0000            0.9074           0.9783
Neg Pred Value              1.0000            0.9896           0.9519
Prevalence                  0.3333            0.3333           0.3333
Detection Rate              0.3333            0.3267           0.3000
Detection Prevalence        0.3333            0.3600           0.3067
Balanced Accuracy           1.0000            0.9650           0.9450</code></pre>
</div>
</div>
<div id="random-forest-model" class="section level3">
<h3>Random Forest Model</h3>
<p>A random forest allows us to determine the most important predictors
across the explanatory variables by generating many decision trees and
then ranking the variables by importance.</p>
<div id="step-1-fitting-the-random-forest-model" class="section level4">
<h4>Step 1: Fitting the random forest model</h4>
<pre class="r"><code>model_rf &lt;- randomForest(Species ~ ., data = iris, ntree = 100)

# Print model summary
print(model_rf)</code></pre>
<pre><code>
Call:
 randomForest(formula = Species ~ ., data = iris, ntree = 100) 
               Type of random forest: classification
                     Number of trees: 100
No. of variables tried at each split: 2

        OOB estimate of  error rate: 6%
Confusion matrix:
           setosa versicolor virginica class.error
setosa         50          0         0        0.00
versicolor      0         47         3        0.06
virginica       0          6        44        0.12</code></pre>
</div>
<div id="step-2-making-predictions-and-model-evaluation"
class="section level4">
<h4>Step 2: Making predictions and model evaluation</h4>
<pre class="r"><code># Make predictions and evaluate
rf_predictions &lt;- predict(model_rf)
conf_matrix_rf &lt;- confusionMatrix(rf_predictions, iris$Species)
print(&quot;Random Forest Confusion Matrix:&quot;)</code></pre>
<pre><code>[1] &quot;Random Forest Confusion Matrix:&quot;</code></pre>
<pre class="r"><code>print(conf_matrix_rf)</code></pre>
<pre><code>Confusion Matrix and Statistics

            Reference
Prediction   setosa versicolor virginica
  setosa         50          0         0
  versicolor      0         47         6
  virginica       0          3        44

Overall Statistics
                                          
               Accuracy : 0.94            
                 95% CI : (0.8892, 0.9722)
    No Information Rate : 0.3333          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.91            
                                          
 Mcnemar&#39;s Test P-Value : NA              

Statistics by Class:

                     Class: setosa Class: versicolor Class: virginica
Sensitivity                 1.0000            0.9400           0.8800
Specificity                 1.0000            0.9400           0.9700
Pos Pred Value              1.0000            0.8868           0.9362
Neg Pred Value              1.0000            0.9691           0.9417
Prevalence                  0.3333            0.3333           0.3333
Detection Rate              0.3333            0.3133           0.2933
Detection Prevalence        0.3333            0.3533           0.3133
Balanced Accuracy           1.0000            0.9400           0.9250</code></pre>
</div>
</div>
</div>
<div id="cross-validation" class="section level2">
<h2>Cross-Validation</h2>
<p>Is a technique used to assess the generalisability of a model to new
data. It involves dividing the dataset into multiple folds and training
the model on each fold while using the remaining set for validation.</p>
<div id="cross-validation-with-pls-da." class="section level3">
<h3>Cross-Validation with PLS-DA.</h3>
<p>This function performs a 10-fold cross-validation on a given data set
using Partial Least Squares (PLS) model. To assess the prediction
ability of the model, a 10-fold cross-validation is conducted by
generating splits with a ratio 1:9 of the data set. Permutation testing
was undertaken to estimate the classification/regression performance of
predictors.</p>
<pre class="r"><code>library(KODAMA)
data(iris)
data=iris[,-5]
labels=iris[,5]
pp=pls.double.cv(data,labels)</code></pre>
<pre><code>..........</code></pre>
<pre class="r"><code>print(pp$Q2Y)</code></pre>
<pre><code> [1] 0.5708579 0.5644874 0.5684284 0.5676491 0.5577177 0.5650870 0.5662088
 [8] 0.5682598 0.5632832 0.5629809</code></pre>
<pre class="r"><code>table(pp$Ypred,labels)</code></pre>
<pre><code>            labels
             setosa versicolor virginica
  setosa         49          0         0
  versicolor      1         33         9
  virginica       0         17        41</code></pre>
</div>
</div>
<div id="feature-transformation" class="section level2">
<h2>Feature transformation</h2>
<p>Is the process of modifying and converting input features of a data
set by applying mathematical operations to improve the learning and
prediction performance of ML models.</p>
<p>Transformation techniques include scaling, normalisation and
logarithmisation, which deal with differences in scale and distribution
between features, non-linearity and outliers.</p>
<p>Input features (variables) may have different units, e.g. kilometre,
day, year, etc., and so the variables have different scales and probably
different distributions which increases the learning difficulty of ML
algorithms from the data.</p>
<div id="normalisation" class="section level3">
<h3>Normalisation</h3>
<p>A number of different normalization methods are provided in
KODAMA:</p>
<p>“none”: no normalization method is applied.</p>
<p>“pqn”: the Probabilistic Quotient Normalization is computed as
described in Dieterle, et al. (2006).</p>
<p>“sum”: samples are normalized to the sum of the absolute value of all
variables for a given sample.</p>
<p>“median”: samples are normalized to the median value of all variables
for a given sample.</p>
<p>“sqrt”: samples are normalized to the root of the sum of the squared
value of all variables for a given sample.</p>
<pre class="r"><code>library(KODAMA)

data(MetRef)
u=MetRef$data;
u=u[,-which(colSums(u)==0)]
u=normalization(u)$newXtrain
class=as.numeric(as.factor(MetRef$gender))
cc=pca(u)
plot(cc$x,pch=21,bg=class)</code></pre>
<p><img src="figure/Supervised_learning.Rmd/normalisation-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-normalisation-1">
Past versions of normalisation-1.png
</button>
</p>
<div id="fig-normalisation-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/tkcaccia/Tutorials/blob/897778af75990c4268c8b31f4717b5182769c81b/docs/figure/Supervised_learning.Rmd/normalisation-1.png" target="_blank">897778a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="scaling-and-standardisation" class="section level3">
<h3>Scaling and Standardisation</h3>
<p>A number of different scaling methods are provided in KODAMA:</p>
<ul>
<li><p>“<code>none</code>”: no scaling method is applied.</p></li>
<li><p>“<code>centering</code>”: centers the mean to zero.</p></li>
<li><p>“<code>autoscaling</code>”: centers the mean to zero and scales
data by dividing each variable by the variance.</p></li>
<li><p>“<code>rangescaling</code>”: centers the mean to zero and scales
data by dividing each variable by the difference between the minimum and
the maximum value.</p></li>
<li><p>“<code>paretoscaling</code>”: centers the mean to zero and scales
data by dividing each variable by the square root of the standard
deviation. Unit scaling divides each variable by the standard deviation
so that each variance equal to 1.</p></li>
</ul>
<pre class="r"><code>library(KODAMA)
data(MetRef)
u=MetRef$data;
u=u[,-which(colSums(u)==0)]
u=scaling(u)$newXtrain
class=as.numeric(as.factor(MetRef$gender))
cc=pca(u)
plot(cc$x,pch=21,bg=class,xlab=cc$txt[1],ylab=cc$txt[2])</code></pre>
<p><img src="figure/Supervised_learning.Rmd/scaling-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-scaling-1">
Past versions of scaling-1.png
</button>
</p>
<div id="fig-scaling-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/tkcaccia/Tutorials/blob/897778af75990c4268c8b31f4717b5182769c81b/docs/figure/Supervised_learning.Rmd/scaling-1.png" target="_blank">897778a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We can combine both normalisation and scaling to see the difference
in the output</p>
<pre class="r"><code>library(KODAMA)
data(MetRef)
u=MetRef$data;
u=u[,-which(colSums(u)==0)]
u=normalization(u)$newXtrain
u=scaling(u)$newXtrain
class=as.numeric(as.factor(MetRef$gender))
cc=pca(u)
plot(cc$x,pch=21,bg=class,xlab=cc$txt[1],ylab=cc$txt[2])</code></pre>
<p><img src="figure/Supervised_learning.Rmd/both-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-both-1">
Past versions of both-1.png
</button>
</p>
<div id="fig-both-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/tkcaccia/Tutorials/blob/897778af75990c4268c8b31f4717b5182769c81b/docs/figure/Supervised_learning.Rmd/both-1.png" target="_blank">897778a</a>
</td>
<td>
tkcaccia
</td>
<td>
2024-09-16
</td>
</tr>
</tbody>
</table>
</div>
</div>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.3.3 (2024-02-29)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS Sonoma 14.5

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/Bogota
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] KODAMA_3.1           umap_0.2.10.0        Rtsne_0.17          
 [4] minerva_1.5.10       randomForest_4.7-1.1 rpart.plot_3.1.2    
 [7] rpart_4.1.23         class_7.3-22         pROC_1.18.5         
[10] reshape2_1.4.4       caret_6.0-94         lattice_0.22-6      
[13] ggplot2_3.5.1        workflowr_1.7.1     

loaded via a namespace (and not attached):
 [1] rlang_1.1.4          magrittr_2.0.3       git2r_0.33.0        
 [4] e1071_1.7-14         compiler_4.3.3       getPass_0.2-4       
 [7] mgcv_1.9-1           png_0.1-8            callr_3.7.6         
[10] vctrs_0.6.5          stringr_1.5.1        pkgconfig_2.0.3     
[13] fastmap_1.2.0        labeling_0.4.3       utf8_1.2.4          
[16] promises_1.3.0       rmarkdown_2.27       prodlim_2024.06.25  
[19] ps_1.7.7             purrr_1.0.2          xfun_0.46           
[22] cachem_1.1.0         jsonlite_1.8.8       recipes_1.0.10      
[25] highr_0.11           later_1.3.2          parallel_4.3.3      
[28] R6_2.5.1             bslib_0.8.0          stringi_1.8.4       
[31] reticulate_1.39.0    parallelly_1.38.0    lubridate_1.9.3     
[34] jquerylib_0.1.4      Rcpp_1.0.13          iterators_1.0.14    
[37] knitr_1.48           future.apply_1.11.2  httpuv_1.6.15       
[40] Matrix_1.6-5         splines_4.3.3        nnet_7.3-19         
[43] timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.16.0   
[46] yaml_2.3.10          timeDate_4032.109    codetools_0.2-20    
[49] processx_3.8.4       listenv_0.9.1        tibble_3.2.1        
[52] plyr_1.8.9           withr_3.0.1          askpass_1.2.0       
[55] evaluate_0.24.0      future_1.34.0        survival_3.7-0      
[58] proxy_0.4-27         pillar_1.9.0         whisker_0.4.1       
[61] foreach_1.5.2        stats4_4.3.3         generics_0.1.3      
[64] rprojroot_2.0.4      munsell_0.5.1        scales_1.3.0        
[67] globals_0.16.3       glue_1.7.0           tools_4.3.3         
[70] data.table_1.15.4    RSpectra_0.16-2      ModelMetrics_1.2.2.2
[73] gower_1.0.1          fs_1.6.4             grid_4.3.3          
[76] ipred_0.9-15         colorspace_2.1-1     nlme_3.1-165        
[79] cli_3.6.3            fansi_1.0.6          lava_1.8.0          
[82] dplyr_1.1.4          gtable_0.3.5         sass_0.4.9          
[85] digest_0.6.36        farver_2.1.2         htmltools_0.5.8.1   
[88] lifecycle_1.0.4      hardhat_1.3.1        httr_1.4.7          
[91] openssl_2.2.1        MASS_7.3-60.0.1     </code></pre>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
